{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***@Author: Ranjith G C***\n",
    "<br>\n",
    "***@Date: 2021-09-12***\n",
    "<br>\n",
    "***@Last Modified by: Ranjith G C***\n",
    "<br>@\n",
    "***Last Modified time: 2021-09-12***\n",
    "<br>\n",
    "***@Title : Program Aim to process and clean stock data and saving into model using mllib and pyspark***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName('Stock Data processing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000/kafka_stock_data/data.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing  The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1=df.withColumnRenamed('[\"time\"','time')\\\n",
    "    .withColumnRenamed(' \"open\"','open')\\\n",
    "    .withColumnRenamed(' \"high\"','high')\\\n",
    "    .withColumnRenamed(' \"low\"','low')\\\n",
    "    .withColumnRenamed(' \"close\"','close')\\\n",
    "    .withColumnRenamed(' \"volume\"]','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+-----------+-----------+----------+\n",
      "|                time|       open|       high|        low|      close|    volume|\n",
      "+--------------------+-----------+-----------+-----------+-----------+----------+\n",
      "|[\"2021-09-03 19:0...|   \"139.55\"|   \"139.55\"|   \"139.55\"|   \"139.55\"|   \"2749\"]|\n",
      "|[\"2021-09-03 17:4...|   \"139.65\"|   \"139.65\"|   \"139.65\"|   \"139.65\"|    \"150\"]|\n",
      "|[\"2021-09-03 16:1...|   \"139.58\"|   \"139.61\"|   \"139.55\"|   \"139.55\"|  \"31003\"]|\n",
      "|[\"2021-09-03 16:0...|  \"139.765\"|  \"139.885\"|   \"139.54\"|   \"139.62\"| \"269779\"]|\n",
      "|[\"2021-09-03 15:4...|   \"139.69\"|  \"139.769\"|  \"139.635\"|  \"139.769\"|  \"79292\"]|\n",
      "|[\"2021-09-03 15:3...| \"139.8399\"|   \"139.86\"|  \"139.655\"|   \"139.69\"|  \"49114\"]|\n",
      "|[\"2021-09-03 15:1...|   \"139.76\"|   \"139.88\"|   \"139.75\"|   \"139.83\"|  \"50153\"]|\n",
      "|[\"2021-09-03 15:0...|   \"139.78\"|   \"139.84\"|   \"139.72\"|   \"139.74\"|  \"38715\"]|\n",
      "|[\"2021-09-03 14:4...|   \"139.61\"|   \"139.78\"|   \"139.59\"|   \"139.78\"|  \"31959\"]|\n",
      "|[\"2021-09-03 14:3...| \"139.6829\"| \"139.6861\"|   \"139.57\"| \"139.6311\"|  \"31552\"]|\n",
      "|[\"2021-09-03 14:1...|   \"139.63\"|   \"139.72\"|   \"139.57\"|   \"139.69\"|  \"34371\"]|\n",
      "|[\"2021-09-03 14:0...|   \"139.76\"|   \"139.76\"|   \"139.63\"|   \"139.64\"|  \"36656\"]|\n",
      "|[\"2021-09-03 13:4...|   \"139.69\"|   \"139.78\"|   \"139.65\"|   \"139.76\"|  \"28612\"]|\n",
      "|[\"2021-09-03 13:3...|   \"139.65\"|   \"139.73\"|  \"139.629\"|   \"139.67\"|  \"30235\"]|\n",
      "|[\"2021-09-03 13:1...|   \"139.49\"|   \"139.65\"|   \"139.48\"|   \"139.64\"|  \"35199\"]|\n",
      "|[\"2021-09-03 13:0...|   \"139.46\"|  \"139.515\"| \"139.4104\"|   \"139.47\"|  \"32583\"]|\n",
      "|[\"2021-09-03 12:4...|   \"139.45\"|   \"139.47\"|   \"139.35\"|   \"139.46\"|  \"34212\"]|\n",
      "|[\"2021-09-03 12:3...|   \"139.47\"|    \"139.5\"|   \"139.33\"|   \"139.43\"|  \"34336\"]|\n",
      "|[\"2021-09-03 12:1...| \"139.4451\"|   \"139.54\"|   \"139.39\"|   \"139.52\"|  \"35873\"]|\n",
      "|[\"2021-09-03 12:0...| \"139.5201\"|   \"139.56\"|   \"139.43\"|   \"139.48\"|  \"32806\"]|\n",
      "+--------------------+-----------+-----------+-----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2 = dfs1.withColumn('open', regexp_replace('open', '\"', ''))\\\n",
    "    .withColumn('Time', regexp_replace('time', '\\\\[\"', ''))\\\n",
    "    .withColumn('Time', regexp_replace('time', '\"', ''))\\\n",
    "    .withColumn('High', regexp_replace('high', '\"', ''))\\\n",
    "    .withColumn('Low', regexp_replace('low', '\"', ''))\\\n",
    "    .withColumn('Close', regexp_replace('close', '\"', ''))\\\n",
    "    .withColumn('Volume', regexp_replace('volume', '\"', ''))\\\n",
    "    .withColumn('Volume', regexp_replace('volume', '\\\\]', ''))\\\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# casting string to double values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs3 = dfs2\\\n",
    "    .withColumn(\"open\",col(\"Open\").cast(\"double\"))\\\n",
    "    .withColumn(\"high\",col(\"High\").cast(\"double\"))\\\n",
    "    .withColumn(\"low\",col(\"Low\").cast(\"double\"))\\\n",
    "    .withColumn(\"close\",col(\"Close\").cast(\"double\"))\\\n",
    "    .withColumn(\"volume\",col(\"Volume\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+--------+\n",
      "|               Time|    open|    high|     low|   close|  volume|\n",
      "+-------------------+--------+--------+--------+--------+--------+\n",
      "|2021-09-03 19:00:00|  139.55|  139.55|  139.55|  139.55|  2749.0|\n",
      "|2021-09-03 17:45:00|  139.65|  139.65|  139.65|  139.65|   150.0|\n",
      "|2021-09-03 16:15:00|  139.58|  139.61|  139.55|  139.55| 31003.0|\n",
      "|2021-09-03 16:00:00| 139.765| 139.885|  139.54|  139.62|269779.0|\n",
      "|2021-09-03 15:45:00|  139.69| 139.769| 139.635| 139.769| 79292.0|\n",
      "|2021-09-03 15:30:00|139.8399|  139.86| 139.655|  139.69| 49114.0|\n",
      "|2021-09-03 15:15:00|  139.76|  139.88|  139.75|  139.83| 50153.0|\n",
      "|2021-09-03 15:00:00|  139.78|  139.84|  139.72|  139.74| 38715.0|\n",
      "|2021-09-03 14:45:00|  139.61|  139.78|  139.59|  139.78| 31959.0|\n",
      "|2021-09-03 14:30:00|139.6829|139.6861|  139.57|139.6311| 31552.0|\n",
      "|2021-09-03 14:15:00|  139.63|  139.72|  139.57|  139.69| 34371.0|\n",
      "|2021-09-03 14:00:00|  139.76|  139.76|  139.63|  139.64| 36656.0|\n",
      "|2021-09-03 13:45:00|  139.69|  139.78|  139.65|  139.76| 28612.0|\n",
      "|2021-09-03 13:30:00|  139.65|  139.73| 139.629|  139.67| 30235.0|\n",
      "|2021-09-03 13:15:00|  139.49|  139.65|  139.48|  139.64| 35199.0|\n",
      "|2021-09-03 13:00:00|  139.46| 139.515|139.4104|  139.47| 32583.0|\n",
      "|2021-09-03 12:45:00|  139.45|  139.47|  139.35|  139.46| 34212.0|\n",
      "|2021-09-03 12:30:00|  139.47|   139.5|  139.33|  139.43| 34336.0|\n",
      "|2021-09-03 12:15:00|139.4451|  139.54|  139.39|  139.52| 35873.0|\n",
      "|2021-09-03 12:00:00|139.5201|  139.56|  139.43|  139.48| 32806.0|\n",
      "+-------------------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "check_na = dfs3.toPandas()\n",
    "check_na1 = check_na.set_index(\"Time\")\n",
    "check_na1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating vectors from features\n",
    "# Apache MLlib takes input in vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|features                |\n",
      "+------------------------+\n",
      "|[139.55,139.55,139.55]  |\n",
      "|[139.65,139.65,139.65]  |\n",
      "|[139.58,139.61,139.55]  |\n",
      "|[139.765,139.885,139.54]|\n",
      "|[139.69,139.769,139.635]|\n",
      "+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureassembler=VectorAssembler(inputCols=[\"open\",\"high\",\"low\"],outputCol=\"features\")\n",
    "output=featureassembler.transform(dfs3)\n",
    "output.select(\"features\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finalized_data consist of features and label which is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"time\",\"features\",\"close\").sort(\"time\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------+\n",
      "|               time|            features| close|\n",
      "+-------------------+--------------------+------+\n",
      "|2021-08-09 04:15:00|[142.96,143.8,142.5]| 142.5|\n",
      "|2021-08-09 07:15:00|[142.4,142.63,142.4]|142.55|\n",
      "|2021-08-09 07:45:00| [142.7,142.8,142.7]| 142.8|\n",
      "|2021-08-09 08:00:00| [142.7,142.7,142.7]| 142.7|\n",
      "|2021-08-09 08:15:00|[142.446,143.2499...|142.33|\n",
      "+-------------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = finalized_data.withColumn(\"rank\",percent_rank().over(Window.partitionBy().orderBy(\"time\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data.where(\"rank <= .8\").drop(\"rank\")\n",
    "test_data = final_data.where(\"rank > .8\").drop(\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of DataFrame[time: string, features: vector, close: double]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.write.(\"test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_reg=LinearRegression(featuresCol='features',labelCol='close')\n",
    "lr_model=linear_reg.fit(train_data)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our Linear Regression model to make some predictions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = lr_model.transform(test_data)\n",
    "predDF.select(\"features\", \"close\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE\n",
    "### RMSE is a metric that ranges from zero to infinity. The closer it is to zero, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "predictionCol=\"prediction\",\n",
    "labelCol=\"close\",\n",
    "metricName=\"rmse\")\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "print(f\"RMSE is {rmse:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.save(\"lrm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "lrcvModel = LinearRegressionModel.load('/user/ubunta/lrm_model')\n",
    "output = lrcvModel.transform(test_data)\n",
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}